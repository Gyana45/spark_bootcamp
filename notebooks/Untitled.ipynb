{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b71133-5b07-40ab-a901-a43243b97324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbfbdb04-75c2-4d1f-b4c3-aca55daa32ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/02 10:20:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "                    .builder\\\n",
    "                    .master(\"spark://spark-master:7077\")\\\n",
    "                    .appName(\"Day_6_DataFrame_2\")\\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff8200a-6b19-471a-afee-ace27f666c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1d3797d-d56d-40e9-9942-92135e015c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+------+----------+-------+\n",
      "|emp_id|emp_name|dept_id|salary|manager_id|emp_age|\n",
      "+------+--------+-------+------+----------+-------+\n",
      "|     1|   Ankit|    100| 10000|         4|     39|\n",
      "|     2|   Mohit|    100| 15000|         5|     48|\n",
      "|     3|   Vikas|    100| 10000|         4|     37|\n",
      "|     4|   Rohit|    100|  5000|         2|     16|\n",
      "|     5|   Mudit|    200| 12000|         6|     55|\n",
      "|     6|    Agam|    200| 12000|         2|     14|\n",
      "|     7|  Sanjay|    200|  9000|         2|     13|\n",
      "|     8|  Ashish|    200|  5000|         2|     12|\n",
      "|     9|  Mukesh|    300|  6000|         6|     51|\n",
      "|    10|  Rakesh|    500|  7000|         6|     50|\n",
      "+------+--------+-------+------+----------+-------+\n",
      "\n",
      "+-------+--------------+\n",
      "|dept_id|     dept_name|\n",
      "+-------+--------------+\n",
      "|    100|     Analytics|\n",
      "|    200|            IT|\n",
      "|    300|            HR|\n",
      "|    400|Text Analytics|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df1.join(df2,['col1','col2'],'inner')\n",
    "\n",
    "employee_schema = StructType([\n",
    "                            StructField(\"emp_id\", IntegerType(), True),\n",
    "                            StructField(\"emp_name\", StringType(), True),\n",
    "                            StructField(\"dept_id\", IntegerType(), True),\n",
    "                            StructField(\"salary\", IntegerType(), True),\n",
    "                            StructField(\"manager_id\", IntegerType(), True),\n",
    "                            StructField(\"emp_age\", IntegerType(), True)\n",
    "                            ])\n",
    "\n",
    "employee_data = [\n",
    "(1, \"Ankit\", 100, 10000, 4, 39),\n",
    "(2, \"Mohit\", 100, 15000, 5, 48),\n",
    "(3, \"Vikas\", 100, 10000, 4, 37),\n",
    "(4, \"Rohit\", 100, 5000, 2, 16),\n",
    "(5, \"Mudit\", 200, 12000, 6, 55),\n",
    "(6, \"Agam\", 200, 12000, 2, 14),\n",
    "(7, \"Sanjay\", 200, 9000, 2, 13),\n",
    "(8, \"Ashish\", 200, 5000, 2, 12),\n",
    "(9, \"Mukesh\", 300, 6000, 6, 51),\n",
    "(10, \"Rakesh\", 500, 7000, 6, 50)\n",
    "]\n",
    "employee_df = spark.createDataFrame(employee_data, employee_schema)\n",
    "\n",
    "dept_schema = StructType([\n",
    "StructField(\"dept_id\", IntegerType(), True),\n",
    "StructField(\"dept_name\", StringType(), True)\n",
    "])\n",
    "dept_data = [\n",
    "(100, \"Analytics\"),\n",
    "(200, \"IT\"),\n",
    "(300, \"HR\"),\n",
    "(400, \"Text Analytics\")\n",
    "]\n",
    "dept_df = spark.createDataFrame(dept_data, dept_schema)\n",
    "\n",
    "employee_df.show()\n",
    "dept_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061216d6-cc8e-403f-8151-7a9af63bf773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:========================================>             (151 + 4) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|dept_id|sum(salary)|\n",
      "+-------+-----------+\n",
      "|    100|      40000|\n",
      "|    200|      38000|\n",
      "|    500|       7000|\n",
      "|    300|       6000|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "employee_df.groupBy(col('dept_id')).agg(sum('salary')).orderBy(sum(col('salary')).desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed898f72-215b-4efc-a32f-3111886d1ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/02 10:32:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 17:=============================================>        (167 + 4) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+------+----------+-------+-----------------+----------+\n",
      "|emp_id|emp_name|dept_id|salary|manager_id|emp_age|total_salary_dept|dense_rank|\n",
      "+------+--------+-------+------+----------+-------+-----------------+----------+\n",
      "|     1|   Ankit|    100| 10000|         4|     39|            40000|         1|\n",
      "|     2|   Mohit|    100| 15000|         5|     48|            40000|         1|\n",
      "|     3|   Vikas|    100| 10000|         4|     37|            40000|         1|\n",
      "|     4|   Rohit|    100|  5000|         2|     16|            40000|         1|\n",
      "|     5|   Mudit|    200| 12000|         6|     55|            38000|         2|\n",
      "|     6|    Agam|    200| 12000|         2|     14|            38000|         2|\n",
      "|     7|  Sanjay|    200|  9000|         2|     13|            38000|         2|\n",
      "|     8|  Ashish|    200|  5000|         2|     12|            38000|         2|\n",
      "|    10|  Rakesh|    500|  7000|         6|     50|             7000|         3|\n",
      "|     9|  Mukesh|    300|  6000|         6|     51|             6000|         4|\n",
      "+------+--------+-------+------+----------+-------+-----------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy('dept_id')\n",
    "window_spec2=Window.orderBy(col('total_salary_dept').desc())\n",
    "\n",
    "employee_df.withColumn('total_salary_dept',sum('salary').over(window_spec))\\\n",
    "            .withColumn('dense_rank',dense_rank().over(window_spec2))\\\n",
    "            .orderBy(col('dense_rank')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ed0a6c-e64f-4cf3-9e3c-bfc72267dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1003f0f-b45c-404d-bf33-599c3c9b8dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
